{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Manh'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userHome_path = os.path.expanduser(\"~\")\n",
    "userHome_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Manh\\\\Documents\\\\hive\\\\spark_warehouse'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = \"Documents\" + os.path.sep + \"hive\" + os.path.sep + \"spark_warehouse\" \n",
    "\n",
    "warehouse_dir = os.path.join(userHome_path, dir_path)\n",
    "warehouse_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Hive Integration\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_dir) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------+---------------+\n",
      "|order_id|         order_date|customer_id|   order_status|\n",
      "+--------+-------------------+-----------+---------------+\n",
      "|       1|2013-07-25 00:00:00|      11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|        256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|      12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|       8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|      11318|       COMPLETE|\n",
      "+--------+-------------------+-----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"./dataset/orders_wh.csv\", header=True, inferSchema=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"orders_temp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS sparksql_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|  namespace|\n",
      "+-----------+\n",
      "|    default|\n",
      "|sparksql_db|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Managed Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE TABLE IF NOT EXISTS sparksql_db.orders_managed AS SELECT * FROM orders_temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+-----------+\n",
      "|  namespace|     tableName|isTemporary|\n",
      "+-----------+--------------+-----------+\n",
      "|sparksql_db|orders_managed|      false|\n",
      "|           |   orders_temp|       true|\n",
      "+-----------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES in sparksql_db\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+-------+\n",
      "|    col_name|data_type|comment|\n",
      "+------------+---------+-------+\n",
      "|    order_id|      int|   NULL|\n",
      "|  order_date|timestamp|   NULL|\n",
      "| customer_id|      int|   NULL|\n",
      "|order_status|   string|   NULL|\n",
      "+------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE sparksql_db.orders_managed\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+--------------------------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                                       |comment|\n",
      "+----------------------------+--------------------------------------------------------------------------------+-------+\n",
      "|order_id                    |int                                                                             |NULL   |\n",
      "|order_date                  |timestamp                                                                       |NULL   |\n",
      "|customer_id                 |int                                                                             |NULL   |\n",
      "|order_status                |string                                                                          |NULL   |\n",
      "|                            |                                                                                |       |\n",
      "|# Detailed Table Information|                                                                                |       |\n",
      "|Catalog                     |spark_catalog                                                                   |       |\n",
      "|Database                    |sparksql_db                                                                     |       |\n",
      "|Table                       |orders_managed                                                                  |       |\n",
      "|Owner                       |Manh                                                                            |       |\n",
      "|Created Time                |Wed Dec 11 20:04:11 KRAT 2024                                                   |       |\n",
      "|Last Access                 |UNKNOWN                                                                         |       |\n",
      "|Created By                  |Spark 3.5.3                                                                     |       |\n",
      "|Type                        |MANAGED                                                                         |       |\n",
      "|Provider                    |hive                                                                            |       |\n",
      "|Table Properties            |[transient_lastDdlTime=1733922255]                                              |       |\n",
      "|Statistics                  |2862178 bytes                                                                   |       |\n",
      "|Location                    |file:/C:/Users/Manh/Documents/hive/spark_warehouse/sparksql_db.db/orders_managed|       |\n",
      "|Serde Library               |org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe                              |       |\n",
      "|InputFormat                 |org.apache.hadoop.mapred.TextInputFormat                                        |       |\n",
      "|OutputFormat                |org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat                      |       |\n",
      "|Storage Properties          |[serialization.format=1]                                                        |       |\n",
      "|Partition Provider          |Catalog                                                                         |       |\n",
      "+----------------------------+--------------------------------------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE EXTENDED sparksql_db.orders_managed\").show(30, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create External Table from Managed Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS sparksql_db.orders_external (\n",
    "    order_id int,\n",
    "    order_date timestamp,\n",
    "    customer_id int,\n",
    "    order_status string\n",
    ")\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "LINES TERMINATED BY '\\n'\n",
    "LOCATION 'file:/C:/Users/Manh/Documents/hive/spark_warehouse/sparksql_db.db/orders_managed'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+-----------+\n",
      "|  namespace|      tableName|isTemporary|\n",
      "+-----------+---------------+-----------+\n",
      "|sparksql_db|orders_external|      false|\n",
      "|sparksql_db| orders_managed|      false|\n",
      "|           |    orders_temp|       true|\n",
      "+-----------+---------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES in sparksql_db\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+--------------------------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                                       |comment|\n",
      "+----------------------------+--------------------------------------------------------------------------------+-------+\n",
      "|order_id                    |int                                                                             |NULL   |\n",
      "|order_date                  |timestamp                                                                       |NULL   |\n",
      "|customer_id                 |int                                                                             |NULL   |\n",
      "|order_status                |string                                                                          |NULL   |\n",
      "|                            |                                                                                |       |\n",
      "|# Detailed Table Information|                                                                                |       |\n",
      "|Catalog                     |spark_catalog                                                                   |       |\n",
      "|Database                    |sparksql_db                                                                     |       |\n",
      "|Table                       |orders_external                                                                 |       |\n",
      "|Owner                       |Manh                                                                            |       |\n",
      "|Created Time                |Wed Dec 11 20:04:17 KRAT 2024                                                   |       |\n",
      "|Last Access                 |UNKNOWN                                                                         |       |\n",
      "|Created By                  |Spark 3.5.3                                                                     |       |\n",
      "|Type                        |EXTERNAL                                                                        |       |\n",
      "|Provider                    |hive                                                                            |       |\n",
      "|Table Properties            |[transient_lastDdlTime=1733922257]                                              |       |\n",
      "|Statistics                  |2862178 bytes                                                                   |       |\n",
      "|Location                    |file:/C:/Users/Manh/Documents/hive/spark_warehouse/sparksql_db.db/orders_managed|       |\n",
      "|Serde Library               |org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe                              |       |\n",
      "|InputFormat                 |org.apache.hadoop.mapred.TextInputFormat                                        |       |\n",
      "|OutputFormat                |org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat                      |       |\n",
      "|Storage Properties          |[serialization.format=,, line.delim=\\n, field.delim=,]                          |       |\n",
      "|Partition Provider          |Catalog                                                                         |       |\n",
      "+----------------------------+--------------------------------------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE EXTENDED sparksql_db.orders_external\").show(30, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create External Table from CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS sparksql_db.orders_external_2 (\n",
    "    order_id int,\n",
    "    order_date timestamp,\n",
    "    customer_id int,\n",
    "    order_status string\n",
    ")\n",
    "USING CSV OPTIONS (path 'C:/Users/Manh/Documents/Learning-Spark/dataset/orders_wh.csv')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+-----------+\n",
      "|  namespace|        tableName|isTemporary|\n",
      "+-----------+-----------------+-----------+\n",
      "|sparksql_db|  orders_external|      false|\n",
      "|sparksql_db|orders_external_2|      false|\n",
      "|sparksql_db|   orders_managed|      false|\n",
      "|           |      orders_temp|       true|\n",
      "+-----------+-----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES in sparksql_db\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+------------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                         |comment|\n",
      "+----------------------------+------------------------------------------------------------------+-------+\n",
      "|order_id                    |int                                                               |NULL   |\n",
      "|order_date                  |timestamp                                                         |NULL   |\n",
      "|customer_id                 |int                                                               |NULL   |\n",
      "|order_status                |string                                                            |NULL   |\n",
      "|                            |                                                                  |       |\n",
      "|# Detailed Table Information|                                                                  |       |\n",
      "|Catalog                     |spark_catalog                                                     |       |\n",
      "|Database                    |sparksql_db                                                       |       |\n",
      "|Table                       |orders_external_2                                                 |       |\n",
      "|Owner                       |Manh                                                              |       |\n",
      "|Created Time                |Wed Dec 11 20:04:18 KRAT 2024                                     |       |\n",
      "|Last Access                 |UNKNOWN                                                           |       |\n",
      "|Created By                  |Spark 3.5.3                                                       |       |\n",
      "|Type                        |EXTERNAL                                                          |       |\n",
      "|Provider                    |CSV                                                               |       |\n",
      "|Location                    |file:/C:/Users/Manh/Documents/Learning-Spark/dataset/orders_wh.csv|       |\n",
      "|Serde Library               |org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe                |       |\n",
      "|InputFormat                 |org.apache.hadoop.mapred.SequenceFileInputFormat                  |       |\n",
      "|OutputFormat                |org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat         |       |\n",
      "+----------------------------+------------------------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE EXTENDED sparksql_db.orders_external_2\").show(30, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
