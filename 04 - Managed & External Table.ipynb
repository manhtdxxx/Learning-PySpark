{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Manh'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userHome_path = os.path.expanduser(\"~\")\n",
    "userHome_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Manh\\\\Documents\\\\hive\\\\spark_warehouse'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = \"Documents\" + os.path.sep + \"hive\" + os.path.sep + \"spark_warehouse\" \n",
    "\n",
    "warehouse_dir = os.path.join(userHome_path, dir_path)\n",
    "warehouse_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Hive Integration\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_dir) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Temp View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------------+-----------+---------------+\n",
      "|order_id|         order_date|customer_id|   order_status|\n",
      "+--------+-------------------+-----------+---------------+\n",
      "|       1|2013-07-25 00:00:00|      11599|         CLOSED|\n",
      "|       2|2013-07-25 00:00:00|        256|PENDING_PAYMENT|\n",
      "|       3|2013-07-25 00:00:00|      12111|       COMPLETE|\n",
      "|       4|2013-07-25 00:00:00|       8827|         CLOSED|\n",
      "|       5|2013-07-25 00:00:00|      11318|       COMPLETE|\n",
      "+--------+-------------------+-----------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"./dataset/orders_wh.csv\", header=True, inferSchema=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"temp_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS test_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "|  test_db|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Managed Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS test_db.managed_table\")\n",
    "spark.sql(\"CREATE TABLE IF NOT EXISTS test_db.managed_table AS SELECT * FROM temp_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-----------+\n",
      "|namespace|    tableName|isTemporary|\n",
      "+---------+-------------+-----------+\n",
      "|  test_db|managed_table|      false|\n",
      "|         |   temp_table|       true|\n",
      "+---------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES in test_db\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------------------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                                  |comment|\n",
      "+----------------------------+---------------------------------------------------------------------------+-------+\n",
      "|order_id                    |int                                                                        |NULL   |\n",
      "|order_date                  |timestamp                                                                  |NULL   |\n",
      "|customer_id                 |int                                                                        |NULL   |\n",
      "|order_status                |string                                                                     |NULL   |\n",
      "|                            |                                                                           |       |\n",
      "|# Detailed Table Information|                                                                           |       |\n",
      "|Catalog                     |spark_catalog                                                              |       |\n",
      "|Database                    |test_db                                                                    |       |\n",
      "|Table                       |managed_table                                                              |       |\n",
      "|Owner                       |Manh                                                                       |       |\n",
      "|Created Time                |Tue Jul 08 21:09:03 KRAT 2025                                              |       |\n",
      "|Last Access                 |UNKNOWN                                                                    |       |\n",
      "|Created By                  |Spark 3.5.3                                                                |       |\n",
      "|Type                        |MANAGED                                                                    |       |\n",
      "|Provider                    |hive                                                                       |       |\n",
      "|Table Properties            |[transient_lastDdlTime=1751983748]                                         |       |\n",
      "|Statistics                  |2862178 bytes                                                              |       |\n",
      "|Location                    |file:/C:/Users/Manh/Documents/hive/spark_warehouse/test_db.db/managed_table|       |\n",
      "|Serde Library               |org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe                         |       |\n",
      "|InputFormat                 |org.apache.hadoop.mapred.TextInputFormat                                   |       |\n",
      "|OutputFormat                |org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat                 |       |\n",
      "|Storage Properties          |[serialization.format=1]                                                   |       |\n",
      "|Partition Provider          |Catalog                                                                    |       |\n",
      "+----------------------------+---------------------------------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE EXTENDED test_db.managed_table\").show(100, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create External Table from Managed Table Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS test_db.external_table (\n",
    "    order_id int,\n",
    "    order_date timestamp,\n",
    "    customer_id int,\n",
    "    order_status string\n",
    ")\n",
    "ROW FORMAT DELIMITED\n",
    "FIELDS TERMINATED BY ','\n",
    "LINES TERMINATED BY '\\n'\n",
    "LOCATION 'file:/C:/Users/Manh/Documents/hive/spark_warehouse/test_db.db/managed_table'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+-----------+\n",
      "|namespace|     tableName|isTemporary|\n",
      "+---------+--------------+-----------+\n",
      "|  test_db|external_table|      false|\n",
      "|  test_db| managed_table|      false|\n",
      "|         |    temp_table|       true|\n",
      "+---------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES in test_db\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                    |comment|\n",
      "+----------------------------+-------------------------------------------------------------+-------+\n",
      "|order_id                    |int                                                          |NULL   |\n",
      "|order_date                  |timestamp                                                    |NULL   |\n",
      "|customer_id                 |int                                                          |NULL   |\n",
      "|order_status                |string                                                       |NULL   |\n",
      "|                            |                                                             |       |\n",
      "|# Detailed Table Information|                                                             |       |\n",
      "|Catalog                     |spark_catalog                                                |       |\n",
      "|Database                    |test_db                                                      |       |\n",
      "|Table                       |external_table                                               |       |\n",
      "|Owner                       |Manh                                                         |       |\n",
      "|Created Time                |Tue Jul 08 21:09:10 KRAT 2025                                |       |\n",
      "|Last Access                 |UNKNOWN                                                      |       |\n",
      "|Created By                  |Spark 3.5.3                                                  |       |\n",
      "|Type                        |EXTERNAL                                                     |       |\n",
      "|Provider                    |hive                                                         |       |\n",
      "|Table Properties            |[transient_lastDdlTime=1751983750]                           |       |\n",
      "|Statistics                  |2862178 bytes                                                |       |\n",
      "|Location                    |file:/C:/Users/Manh/Documents/hive/spark_warehouse/test_db.db|       |\n",
      "|Serde Library               |org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe           |       |\n",
      "|InputFormat                 |org.apache.hadoop.mapred.TextInputFormat                     |       |\n",
      "|OutputFormat                |org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat   |       |\n",
      "|Storage Properties          |[serialization.format=,, line.delim=\\n, field.delim=,]       |       |\n",
      "|Partition Provider          |Catalog                                                      |       |\n",
      "+----------------------------+-------------------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE EXTENDED test_db.external_table\").show(100, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create External Table from CSV File Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS test_db.external_table_2\")\n",
    "spark.sql(\"\"\"\n",
    "CREATE EXTERNAL TABLE IF NOT EXISTS test_db.external_table_2 (\n",
    "    order_id int,\n",
    "    order_date timestamp,\n",
    "    customer_id int,\n",
    "    order_status string\n",
    ")\n",
    "USING CSV OPTIONS (path 'C:/Users/Manh/Documents/Learning-Spark/dataset/orders_wh.csv')\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+-----------+\n",
      "|namespace|       tableName|isTemporary|\n",
      "+---------+----------------+-----------+\n",
      "|  test_db|  external_table|      false|\n",
      "|  test_db|external_table_2|      false|\n",
      "|  test_db|   managed_table|      false|\n",
      "|         |      temp_table|       true|\n",
      "+---------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW TABLES in test_db\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+------------------------------------------------------------------+-------+\n",
      "|col_name                    |data_type                                                         |comment|\n",
      "+----------------------------+------------------------------------------------------------------+-------+\n",
      "|order_id                    |int                                                               |NULL   |\n",
      "|order_date                  |timestamp                                                         |NULL   |\n",
      "|customer_id                 |int                                                               |NULL   |\n",
      "|order_status                |string                                                            |NULL   |\n",
      "|                            |                                                                  |       |\n",
      "|# Detailed Table Information|                                                                  |       |\n",
      "|Catalog                     |spark_catalog                                                     |       |\n",
      "|Database                    |test_db                                                           |       |\n",
      "|Table                       |external_table_2                                                  |       |\n",
      "|Owner                       |Manh                                                              |       |\n",
      "|Created Time                |Tue Jul 08 21:10:49 KRAT 2025                                     |       |\n",
      "|Last Access                 |UNKNOWN                                                           |       |\n",
      "|Created By                  |Spark 3.5.3                                                       |       |\n",
      "|Type                        |EXTERNAL                                                          |       |\n",
      "|Provider                    |CSV                                                               |       |\n",
      "|Location                    |file:/C:/Users/Manh/Documents/Learning-Spark/dataset/orders_wh.csv|       |\n",
      "|Serde Library               |org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe                |       |\n",
      "|InputFormat                 |org.apache.hadoop.mapred.SequenceFileInputFormat                  |       |\n",
      "|OutputFormat                |org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat         |       |\n",
      "+----------------------------+------------------------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE EXTENDED test_db.external_table_2\").show(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
